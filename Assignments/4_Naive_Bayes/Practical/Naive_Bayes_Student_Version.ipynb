{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a47252d",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; line-height: 2.5; font-family: 'XB Zar', sans-serif; border: 5px solid #008B8B; border-radius: 15px; margin: 20px;\"> \n",
    "\n",
    "<div style=\"font-family: arial; direction: rtl; padding: 15px 0;\">\n",
    "\n",
    "<h4 style=\"text-align: center;\">به نام خدا</h4>\n",
    "\n",
    "<h2 style=\"text-align: center; color: #103bc9;\">مقدمه‌ای بر داده‌کاوی</h2>\n",
    "\n",
    "<h3 style=\"text-align: center; color: #d42c06;\">دانشگاه علم و صنعت ایران</h3>\n",
    "    \n",
    "<h3 style=\"text-align: center; color: #d42c06;\">دانشکده ریاضی و علوم کامپیوتر</h3>\n",
    "\n",
    "<h4 style=\"padding-top: 7px; text-align: center;\">نیمسال اول سال تحصیلی ۱۴۰۳-۱۴۰۴</h4>\n",
    "\n",
    "<hr style=\"margin-top: 25px; border-color: #fff;\">\n",
    "\n",
    "<h1 style=\"text-align: center; color: #9c0000; margin-bottom: 30px;\">تمرین ۱: بیز ساده</h1>\n",
    "\n",
    "<h3 style=\"text-align: center; margin-top: 20px;\">دکتر مائده السادات طاهائی</h3>\n",
    "\n",
    "<div align=\"center\" style=\"font-size: 20px; margin-top: 20px; line-height: 2;\">طراحان: نرگس قنبری - سارا پورخلیل</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd8f30",
   "metadata": {},
   "source": [
    "<div style=\"font-family: arial; padding: 30px; padding-top: 15px; padding-bottom: 0;\">\n",
    "\n",
    "<hr style=\"margin-top: 25px; border-color: #fff;\">\n",
    "\n",
    "<h2 style=\"text-align: center; color: #186e00;\">بخش ۱:مقدمه</h2>\n",
    "\n",
    "<hr style=\"margin-top: 25px; border-color: #fff;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55662f",
   "metadata": {},
   "source": [
    "<div style=\"font-family: arial; direction: rtl; padding: 30px; padding-top: 0; padding-bottom: 0;\">\n",
    "    \n",
    "<h2 id=\"introduction\" style=\"color: #d42c06;\">بیز ساده</h2>\n",
    "\n",
    "\n",
    "در این تمرین شما الگوریتم بیز ساده را برای یک مسئله شناسایی اسپم پیاده‌سازی خواهید کرد.\n",
    "<a name=\"1\"></a>\n",
    "\n",
    "\n",
    "الگوریتم بیز ساده یکی از سنگ‌ بناهای یادگیری ماشین و علوم داده محسوب می‌شود که از قضیه بیز برای تعیین اینکه آیا یک داده به یک کلاس خاص تعلق دارد استفاده می‌کند. این الگوریتم فرض «ساده‌لوحانه» می‌کند که هر ویژگی به صورت مستقل از دیگر ویژگی‌ها است. این فرض تقریباً به طور قطع در داده‌های شما درست نیست، اما این فرض منجر به پیاده‌سازی یک الگوریتم بسیار ساده‌تر می‌شود و همانطور که خواهید دید، می‌تواند نتایج بسیار مفیدی ایجاد کند. مهم است که بدانید بیز ساده یک الگوریتم نظارت‌شده است، یعنی برای عملکرد صحیح به داده‌های برچسب‌گذاری‌شده نیاز دارد. در مثالی که خواهید دید، این بدان معنی است که مجموعه‌ای از ایمیل‌ها باید قبلاً به عنوان \"اسپم\" یا \"ham\" علامت‌گذاری شده باشند تا الگوریتم آموزش ببیند.\n",
    "\n",
    "### بیز ساده برای شناسایی اسپم\n",
    "\n",
    "این تمرین بر روی یک مسئله طبقه‌بندی دودویی تمرکز دارد: تمایز بین ایمیل‌های اسپم و غیر اسپم، که به طور محاوره‌ای به آن‌ها \"ham\" گفته می‌شود. برای این تمرین، ایمیل‌های اسپم با $1$ و ایمیل‌های غیر اسپم (ham) با $0$ برچسب‌گذاری می‌شوند.\n",
    "\n",
    "احتمالی که برای یک ایمیل مورد توجه است به صورت زیر نمایش داده می‌شود:\n",
    "\n",
    "$$ P(\\text{spam} \\mid \\text{email}) $$\n",
    "\n",
    "هر چه این احتمال بالاتر باشد، احتمال بیشتری وجود دارد که ایمیل به عنوان اسپم طبقه‌بندی شود. قضیه بیز، که در کلاس‌ها دیده‌اید، به این شکل در محاسبه استفاده می‌شود:\n",
    "\n",
    "$$ P(\\text{spam} \\mid \\text{email}) = \\frac{P(\\text{email} \\mid \\text{spam}) \\cdot P(\\text{spam})}{P(\\text{email})} $$\n",
    "\n",
    "در اینجا تفکیک اصطلاحات آمده است:\n",
    "\n",
    "- $ P(\\text{spam}) $: احتمال اینکه یک ایمیل به طور تصادفی انتخاب‌شده اسپم باشد، که معادل نسبت ایمیل‌های اسپم در مجموعه داده است.\n",
    "- $ P(\\text{email} \\mid \\text{spam}) $: احتمال وقوع یک ایمیل خاص با فرض اینکه می‌دانیم اسپم است.\n",
    "- $ P(\\text{email}) $: احتمال کلی وقوع ایمیل.\n",
    "\n",
    "یک \"میانبر\" جالب در این رویکرد این است که می‌توانید عبارت $ P(\\text{email}) $ را نادیده بگیرید. هدف این محاسبه این است که احتمال اینکه یک ایمیل اسپم باشد را با احتمال اینکه یک ایمیل هام باشد مقایسه کنیم. در اینجا عبارت برای هر دو $ P(\\text{spam} \\mid \\text{email}) $ و $ P(\\text{ham} \\mid \\text{email}) $ آمده است:\n",
    "\n",
    "$$ P(\\text{spam} \\mid \\text{email}) = \\frac{P(\\text{email} \\mid \\text{spam}) \\cdot P(\\text{spam})}{P(\\text{email})} $$\n",
    "\n",
    "$$ P(\\text{ham} \\mid \\text{email}) = \\frac{P(\\text{email} \\mid \\text{ham}) \\cdot P(\\text{ham})}{P(\\text{email})} $$\n",
    "\n",
    "از آنجایی که $ P(\\text{email}) > 0 $ است و در هر دو عبارت ظاهر می‌شود، مقایسه دو احتمال فقط نیاز به ارزیابی صورت کسرها دارد و می‌توانید این مخرج را نادیده بگیرید.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a95a7",
   "metadata": {},
   "source": [
    "<h2 id=\"introduction\" style=\"color: #d42c06;\">necessary imports </h2>\n",
    "\n",
    "این بلوک کد تمامی کتابخانه‌ها و توابع لازم برای این تمرین را وارد خواهد کرد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be67d6cd",
   "metadata": {},
   "source": [
    "<h2 id=\"introduction\" style=\"color: #d42c06;\">create a dataframe</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with the data\n",
    "data = {\n",
    "    'text': [\n",
    "        \"Congratulations! You've won a free vacation! lottery\", \"Meeting schedule at 10 AM tomorrow in the conference room.\",\n",
    "        \"Claim your exclusive offer lottery now!\", \"Can you send me the latest report?\", \n",
    "        \"Urgent: Update your account lottery information.\", \"Let's catch up over lunch next week. schedule\",\n",
    "        \"Get your prescription filled at a discount!\", \"Don't forget to submit your expense report.\",\n",
    "        \"You have been selected for a special lottery prize.\", \"Please confirm your attendance for the meeting schedule.\",\n",
    "        \"Limited-time offer! Buy now and save big!\", \"Attached is the report you requested. schedule\",\n",
    "        \"You are pre-approved for a credit card.\", \"Lunch meeting rescheduled to 1 PM.\",\n",
    "        \"Exclusive deal just for you!\", \"Can you review this document?\",\n",
    "        \"Act now and get a 50% lottery discount!\", \"Here's the latest project update.\",\n",
    "        \"Win a free trip to the Bahamas!\", \"Team meeting moved to Tuesday.\",\n",
    "        \"Get free samples today!\", \"Your input is needed on this task.\",\n",
    "        \"You've won a gift card!\", \"Please find the attached files for review.\",\n",
    "        \"Final notice: Claim your lottery reward now.\", \"How about a coffee meeting tomorrow?\",\n",
    "        \"Click here to win big prizes!\", \"Project deadline extended to next week.\",\n",
    "        \"Don't miss out on this opportunity!\", \"Can you join the call at 3 PM?\",\n",
    "        \"Special offer: Buy one, get one free!\", \"Meeting agenda attached.\",\n",
    "        \"Your account has been compromised.\", \"Let's discuss the project details.\",\n",
    "        \"Win exclusive access now!\", \"Can you provide feedback on this?\",\n",
    "        \"Urgent: Your action required immediately.\", \"Please review the attached presentation schedule.\",\n",
    "        \"Huge sale on all items!\", \"Team outing planned for Friday.\",\n",
    "        \"Congratulations! You're a winner!\", \"Here is the report summary.\",\n",
    "        \"Limited-time promotion!\", \"Meeting minutes from today attached.\",\n",
    "        \"Get rich quick with this simple trick!\", \"Follow up on our previous conversation schedule.\",\n",
    "        \"Don't miss this incredible offer!\", \"Project kickoff meeting tomorrow.\",\n",
    "        \"You've been selected for a special lottery reward!\"\n",
    "    ],\n",
    "    'spam': [\n",
    "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
    "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
    "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
    "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
    "        1, 0, 1, 0, 1, 0, 1, 0, 1, \n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "dataframe_emails= pd.DataFrame(data)\n",
    "dataframe_emails.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56016798",
   "metadata": {},
   "source": [
    "<h2 id=\"introduction\" style=\"color: #d42c06;\">proprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eeb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_emails(df):\n",
    "\n",
    "    # Shuffles the dataset\n",
    "    df = df.sample(frac = 1, ignore_index = True, random_state = 42)\n",
    "    # convert email to a numpy array.\n",
    "    X = df.text.to_numpy()\n",
    "    # Convert the labels to numpy array\n",
    "    Y = df.spam.to_numpy()\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001806df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = preprocess_emails(dataframe_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b557d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the below number to print any email that you want\n",
    "email_index = 30\n",
    "print(f\"Email index {email_index}: {X[email_index]}\\n\\n\")\n",
    "print(f\"Class: {Y[email_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6dde9",
   "metadata": {},
   "source": [
    "<h2 id=\"introduction\" style=\"color: #d42c06;\">preprocessing the text </h2>\n",
    "\n",
    "\n",
    "<div dir='rtl'>\n",
    "در متن، معمولاً برخی کلمات اطلاعات زیادی درباره محتوای متن ارائه نمی‌دهند، مانند حروف اضافه، ضمایر و غیره. این‌ها کلمات توقف نامیده می‌شوند. از آنجایی که در هر متنی بسیار متداول هستند، به سختی اطلاعات مفیدی برای کار ما ذخیره می‌کنند. ایده این است که همه این کلمات توقف و علامت‌گذاری‌ها را حذف کنیم، بنابراین در نهایت یک مجموعه ساده‌تر از کلمات برای کار با آن خواهید داشت. این همان کاری است که تابع بعدی انجام می‌دهد.\n",
    "\n",
    "گام دیگر توکن‌سازی ایمیل‌ها است. توکن‌سازی به معنای شکستن ایمیل به توکن‌ها، که اساساً کلمات موجود در آن هستند. در نتیجه، برای هر ایمیل، نتیجه نهایی یک آرایه نامپای خواهد بود که شامل هر کلمه در ایمیل بدون کلمات توقف و علامت‌گذاری‌ها است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(X):\n",
    "    \"\"\"\n",
    "    Preprocesses a collection of text data by removing stopwords and punctuation.\n",
    "\n",
    "    Parameters:\n",
    "    - X (str or array-like): The input text data to be processed. If a single string is provided,\n",
    "      it will be converted into a one-element numpy array.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.array: An array of preprocessed text data, where each element represents a document\n",
    "      with stopwords and punctuation removed.\n",
    "\n",
    "    Note:\n",
    "    - The function uses the Natural Language Toolkit (nltk) library for tokenization and stopword removal.\n",
    "    - If the input is a single string, it is converted into a one-element numpy array.\n",
    "    \"\"\"\n",
    "    # Make a set with the stopwords and punctuation\n",
    "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "\n",
    "    # The next lines will handle the case where a single email is passed instead of an array of emails.\n",
    "    if isinstance(X, str):\n",
    "        X = np.array([X])\n",
    "\n",
    "    # The result will be stored in a list\n",
    "    X_preprocessed = []\n",
    "\n",
    "    for i, email in enumerate(X):\n",
    "        email = np.array([i.lower() for i in word_tokenize(email) if i.lower() not in stop]).astype(X.dtype)\n",
    "        X_preprocessed.append(email)\n",
    "        \n",
    "    if len(X) == 1:\n",
    "        return X_preprocessed[0]\n",
    "    return X_preprocessed\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8af16",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "پس از پیش‌پردازش، متن هر ایمیل به یک آرایه numpy تبدیل شده است که در آن تمام کلمات توقف حذف شده‌اند. مثال زیر نشان می‌دهد که یک ایمیل نمونه قبل و بعد از این مرحله پردازش چگونه به نظر می‌رسد. احساس راحتی کنید تا مقادیر مختلف را امتحان کنید و نتایج این مرحله را بر روی ایمیل‌های مختلف مشاهده کنید. این آرایه تمیز شده از کلمات برای هر ایمیل، همان چیزی است که در واقع توسط الگوریتم استفاده خواهد شد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152114df",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_email=\"marketing for your espeak session  vince :  thanks for your time earlier this week ; i ' m looking forward to your espeak  event .  sarah and i met with our etv contact yesterday , and we will be able to put a  bulleted list on the elevator screens to advertise your espeak . please let  me know what you would like us to post for you , and we will do the rest !  we also have plans to market specifically to the trader community here at  enron , so you should get a high participation rate , especially from those  groups .  thanks , again .  - er\"\n",
    "temp_email_treated=preprocess_text(temp_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Email before preprocessing: {temp_email}\")\n",
    "print(f\"Email after preprocessing: {temp_email_treated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85064b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each string and save the results in a new numpy array \n",
    "X_treated =preprocess_text(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30678bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_index = 20\n",
    "print(f\"Email before preprocessing: {X[email_index]}\")\n",
    "print(f\"Email after preprocessing: {X_treated[email_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f53152",
   "metadata": {},
   "source": [
    "<h2 id=\"introduction\" style=\"color: #d42c06;\">split to train and test</h2>\n",
    "حال بیایید داده‌های خود را به مجموعه‌های آموزشی و آزمایشی تقسیم کنیم. شما با نسبت ۹۰/۱۰ کار خواهید کرد، یعنی ۹۰٪ از داده‌ها برای آموزش و ۱۰٪ برای آزمایش استفاده خواهد شد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(0.90*len(X_treated)) # 80% of the samples will be used to train.\n",
    "\n",
    "X_train = X_treated[:TRAIN_SIZE]\n",
    "Y_train = Y[:TRAIN_SIZE]\n",
    "X_test = X_treated[TRAIN_SIZE:]\n",
    "Y_test = Y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a23c6",
   "metadata": {},
   "source": [
    "<div style=\"font-family: arial; padding: 30px; padding-top: 15px; padding-bottom: 0;\">\n",
    "\n",
    "<hr style=\"margin-top: 25px; border-color: #fff;\">\n",
    "\n",
    "<h2 style=\"text-align: center; color: #186e00;\">بخش 2: پیاده سازی الگوریتم بیز ساده</h2>\n",
    "\n",
    "<hr style=\"margin-top: 25px; border-color: #fff;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c7273",
   "metadata": {},
   "source": [
    "\n",
    "<div dir='rtl'>\n",
    "<a name=\"4\"></a>\n",
    "\n",
    "\n",
    "به یاد داشته باشید که وظیفه شما چیست: مقایسه $P(\\text{spam} \\mid \\text{email})$ و $P(\\text{ham} \\mid \\text{email})$ برای تصمیم‌گیری درباره اینکه کدام یک بزرگتر است. کافی است فقط $P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam})$ و $P(\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham})$ را محاسبه کنید تا مقایسه انجام شود.\n",
    "\n",
    "<a name=\"4.1\"></a>\n",
    "### ۲.۱ محاسبه $P(\\text{email} \\mid \\text{spam})$ و $P(\\text{email} \\mid \\text{ham})$\n",
    "\n",
    "هر دو حالت به‌طور یکسان عمل می‌کنند، بنابراین بیایید با حالت هرزنامه (spam) شروع کنیم.\n",
    "\n",
    "هر ایمیل یک لیست از کلمات است. هدف شما این است که محاسبه کنید چقدر احتمال دارد که این لیست از کلمات را ببینید، با فرض اینکه ایمیل هرزنامه است. روشی که برای این کار استفاده خواهید کرد، اعمال قاعده ضرب است. با نمایش یک ایمیل به صورت $\\text{email} = \\{\\text{word}_1, \\text{word}_2, \\ldots, \\text{word}_n \\}$، محاسبه به صورت زیر است:\n",
    "\n",
    "$$P(\\text{email} \\mid \\text{spam}) = P(\\text{word}_1 \\mid \\text{spam}) \\cdot P(\\text{word}_2 \\mid \\text{spam}) \\cdots P(\\text{word}_n \\mid \\text{spam})$$\n",
    "\n",
    "این‌جا جایی است که شما **فرض ساده** را می‌کنید که منجر به نام \"بیز ساده\" شده است! شما فرض می‌کنید که احتمال ظاهر شدن هر کلمه در یک ایمیل مستقل از احتمال ظاهر شدن سایر کلمات است. این فرض، البته، نادرست است. ایمیل‌هایی که شامل کلمه \"party\" هستند، احتمالاً بیشتر شامل کلمه \"invitation\" نیز خواهند بود. ایمیل‌هایی که شامل کلمه \"prize\" هستند، احتمالاً بیشتر شامل کلمه \"congragulations\" نیز خواهند بود. با این حال، با فرض نادرست اینکه این احتمالات مستقل هستند، شما توانایی اعمال قاعده ضرب را به دست می‌آورید. به جای محاسبه مجموعه‌ای پیچیده از احتمالات شرطی بین کلمات، می‌توانید به سادگی استقلال را فرض کرده و مجموعه‌ای نسبتاً ساده از احتمالات شرطی را همان‌طور که در عبارت بالا نشان داده شده، ضرب کنید. بیز ساده بر اساس یک فرض نادرست درباره داده‌های شما ساخته شده است، اما همان‌طور که خواهید دید، اغلب نتایج چشمگیری به همراه دارد!\n",
    "\n",
    "این‌گونه می‌توانید احتمال ظاهر شدن $\\text{word}_1$ در یک ایمیل را با فرض اینکه هرزنامه است محاسبه کنید:\n",
    "\n",
    "$$P(\\text{word}_1 \\mid \\text{spam}) = \\frac{\\text{\\# spam emails with } \\text{word}_1}{\\text{\\# spam emails}}$$\n",
    "\n",
    "که در آن نماد \\# نشان‌دهنده تعداد عناصر است، یعنی $\\text{\\# spam emails with } \\text{word}_1$ به معنی تعداد ایمیل‌های هرزنامه‌ای است که شامل $\\text{word}_1$ هستند.\n",
    "\n",
    "این واقعاً یک محاسبه بسیار ساده است. تعداد ایمیل‌های هرزنامه‌ای که شامل $\\text{word}_1$ هستند را بشمارید و بر تعداد کل ایمیل‌های هرزنامه تقسیم کنید. از طریق هر کلمه در مجموعه داده‌ها تکرار کنید و فرآیند را تکرار کنید، و شما آماده‌اید تا احتمال کلی مشاهده هر ایمیلی را محاسبه کنید، با فرض اینکه آن ایمیل هرزنامه یا عادی (ham) باشد. با در نظر گرفتن این موضوع، **اولین وظیفه شما ایجاد یک دیکشنری به نام `word_frequency` خواهد بود تا فراوانی ظهور هر کلمه در مجموعه داده‌ها در ایمیل‌های عادی و هرزنامه را ذخیره کند.**\n",
    "\n",
    "#### ۲.۱.۱ مدیریت صفر در ضرب\n",
    "\n",
    "برخورد با کلمه‌ای که فقط در ایمیل‌های هرزنامه ظاهر می‌شود یا هرگز در یک ایمیل هرزنامه ظاهر نمی‌شود ممکن است منجر به $P(\\text{word} \\mid \\text{spam}) = 0$ (یا معادل آن برای ham) شود و منجر به صفر شدن کل ضرب گردد. این سناریو مطلوب نیست زیرا یک کلمه می‌تواند کل احتمال را صفر کند. برای کاهش این مشکل، شما **با شمارش ظهورهای هرزنامه/عادی برای هر کلمه از ۱ شروع خواهید کرد**. با فرض مصنوعی اینکه حداقل یک ایمیل هرزنامه و یک ایمیل عادی با هر کلمه وجود دارد، احتمال صفر شدن در محاسبات را حذف می‌کنید.\n",
    "\n",
    "<a name=\"4.2\"></a>\n",
    "### ۲.۲ محاسبه $P(\\text{spam})$ و $P(\\text{ham})$\n",
    "\n",
    "هنگام استفاده از نظریه بیز، شما همچنین باید احتمال کلی مشاهده ایمیل‌های عادی و هرزنامه را شامل شوید. این محاسبه نسبتاً آسان است زیرا فقط نسبت ایمیل‌های هرزنامه و عادی در مجموعه داده‌ها هستند.\n",
    "\n",
    "$$P(\\text{spam}) = \\frac{\\text{\\# spam emails}}{\\text{\\# total emails}}$$\n",
    "$$P(\\text{ham}) = \\frac{\\text{\\# ham emails}}{\\text{\\# total emails}}$$\n",
    "\n",
    "<a name=\"4.3\"></a>\n",
    "### ۲.۳ جمع‌بندی همه چیز\n",
    "\n",
    "برای محاسبه احتمال اینکه یک ایمیل هرزنامه یا عادی باشد، فقط کافیست عبارات قبلاً محاسبه شده را ضرب کرده و مقایسه کنید که کدامیک بزرگتر است.\n",
    "\n",
    "- $P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam})$\n",
    "- $P(\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham})$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bcac70",
   "metadata": {},
   "source": [
    "<div style=\"font-family: arial; direction: rtl; padding: 30px; padding-top: 0; padding-bottom: 0;\">\n",
    "    \n",
    "<h2 id=\"conclusion\" style=\"color: #d42c06;\">تمرین اول</h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ff895",
   "metadata": {},
   "source": [
    "<a name=\"ex01\"></a>\n",
    "<div dir='rtl'>\n",
    "\n",
    "وظیفه شما این است که تابعی را پیاده‌سازی کنید که یک دیکشنری ایجاد کند و فراوانی ظهور هر کلمه در مجموعه داده‌ها را به عنوان هرزنامه (۱) یا عادی (۰) ثبت کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b017801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency(X,Y):\n",
    "    \"\"\"\n",
    "    Calculate the frequency of each word in a set of emails categorized as spam (1) or not spam (0).\n",
    "\n",
    "    Parameters:\n",
    "    - X (numpy.array): Array of emails, where each email is represented as a list of words.\n",
    "    - Y (numpy.array): Array of labels corresponding to each email in X. 1 indicates spam, 0 indicates ham.\n",
    "\n",
    "    Returns:\n",
    "    - word_dict (dict): A dictionary where keys are unique words found in the emails, and values\n",
    "      are dictionaries containing the frequency of each word for spam (1) and not spam (0) emails.\n",
    "    \"\"\"\n",
    "    # Creates an empty dictionary\n",
    "    word_dict = {}\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    num_emails = None\n",
    "\n",
    "    # Iterates over every processed email and its label\n",
    "    for i in range(num_emails):\n",
    "        # Get the i-th email\n",
    "        email = X[i] \n",
    "        # Get the i-th label. This indicates whether the email is spam or not. 1 = None\n",
    "        # The variable name cls is an abbreviation for class, a reserved word in Python.\n",
    "        cls = Y[i] \n",
    "        # To avoid counting the same word twice in an email, remove duplicates by casting the email as a set\n",
    "        email = set(email) \n",
    "        # Iterates over every distinct word in the email\n",
    "        for word in email:\n",
    "            # If the word is not already in the dictionary, manually add it. Remember that you will start every word count as 1 both in spam and ham\n",
    "            if word not in word_dict.keys():\n",
    "                word_dict[word] = {\"spam\": None, \"ham\": None}\n",
    "            # Add one occurrence for that specific word in the key ham if cls == 0 and spam if cls == 1. \n",
    "            if cls == 0:    \n",
    "                word_dict[None][None] += 1\n",
    "            if cls == 1:\n",
    "                word_dict[None][None] += 1\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = get_word_frequency([['like','going','river'], ['love', 'deep', 'river'], ['hate','river']], [1,0,0])\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b965230",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "خروجی مورد انتظار\n",
    "\n",
    "```Python\n",
    "{'going': {'spam': 2, 'ham': 1}, 'river': {'spam': 2, 'ham': 3}, 'like': {'spam': 2, 'ham': 1}, 'deep': {'spam': 1, 'ham': 2}, 'love': {'spam': 1, 'ham': 2}, 'hate': {'spam': 1, 'ham': 2}}\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6391802",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "برای به‌دست آوردن نسبت هرزنامه‌ها در مجموعه داده‌های آموزشی، می‌توانید به سادگی این کار را انجام دهید:\n",
    "شما همچنین به یک دیکشنری فراوانی کلاس نیاز خواهید داشت. این دیکشنری تعداد کل ایمیل‌های عادی (۰) و هرزنامه (۱) را در مجموعه داده‌ها ذخیره خواهد کرد. خط کد زیر این دیکشنری را برای شما ایجاد خواهد کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c68994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will build the word_frequency dictionary using the training set. \n",
    "word_frequency = get_word_frequency(X_train,Y_train)\n",
    "\n",
    "# To count the spam and ham emails, you may just sum the respective 1 and 0 values in the training dataset, since the convention is spam = 1 and ham = 0.\n",
    "class_frequency = {'ham': sum(Y_train == 0), 'spam': sum(Y_train == 1)}\n",
    "print(class_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f9a4c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: arial; direction: rtl; padding: 30px; padding-top: 0; padding-bottom: 0;\">\n",
    "    \n",
    "<h2 id=\"conclusion\" style=\"color: #d42c06;\">تمرین دوم</h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f5fba",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "\n",
    "در تمرین بعدی، شما تابعی را برای محاسبه $P(\\text{word} \\mid \\text{spam})$ و $P(\\text{word} \\mid \\text{ham})$ پیاده‌سازی خواهید کرد. از آنجا که محاسبات برای هر دو نوع ایمیل یکسان است، شما تابعی ایجاد خواهید کرد که $P(\\text{word} \\mid \\text{class})$ را محاسبه می‌کند، جایی که class می‌تواند اسپم ($1$) یا هام ($0$) باشد.\n",
    "\n",
    "به خاطر داشته باشید که\n",
    "\n",
    "$$P(\\text{word}_i \\mid \\text{class}) = \\frac{\\text{\\# ایمیل‌های موجود در کلاس (اسپم یا هام) که شامل کلمه } \\text{word}_i \\text{ هستند}}{\\text{\\# ایمیل‌های موجود در کلاس مورد نظر (اسپم یا هام)}}$$\n",
    "\n",
    "**توجه داشته باشید که در حال حاضر نگران وجود یا عدم وجود یک کلمه در دیکشنری نخواهید بود. این موضوع در توابع بعدی بررسی خواهد شد.**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_word_given_class(word, cls, word_frequency, class_frequency):\n",
    "    \"\"\"\n",
    "    Calculate the conditional probability of a given word occurring in a specific class.\n",
    "\n",
    "    Parameters:\n",
    "    - word (str): The target word for which the probability is calculated.\n",
    "    - cls (str): The class for which the probability is calculated, it may be 'spam' or 'ham'\n",
    "    - word_frequency (dict): The dictionary containing the words frequency.\n",
    "    - class_frequency (dict): The dictionary containing the class frequency.\n",
    "\n",
    "    Returns:\n",
    "    - float: The conditional probability of the given word occurring in the specified class.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Get the amount of times the word appears with the given class (class is stores in spam variable)\n",
    "    amount_word_and_class = word_frequency[None][None]\n",
    "    p_word_given_class = None/class_frequency[None]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return p_word_given_class\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b789d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"P(lottery | spam) = {prob_word_given_class('lottery', cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
    "print(f\"P(lottery | ham) = {prob_word_given_class('lottery', cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
    "print(f\"P(schedule | spam) = {prob_word_given_class('schedule', cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)}\")\n",
    "print(f\"P(schedule | ham) = {prob_word_given_class('schedule', cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55831a43",
   "metadata": {},
   "source": [
    "<div style=\"font-family: arial; direction: rtl; padding: 30px; padding-top: 0; padding-bottom: 0;\">\n",
    "    \n",
    "<h2 id=\"conclusion\" style=\"color: #d42c06;\">تمرین سوم</h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4412dfc",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "\n",
    "در تمرین بعدی، شما تابعی را برای محاسبه $P(\\text{email} \\mid \\text{class})$ پیاده‌سازی خواهید کرد که در آن class می‌تواند اسپم (1) یا هام (0) باشد. شما از *فرض ساده‌لوحانه* استفاده خواهید کرد که:\n",
    "\n",
    "$$P(\\text{email} \\mid \\text{class}) = P(\\text{word}_1 \\mid \\text{class}) \\cdot P(\\text{word}_2 \\mid \\text{class}) \\cdots P(\\text{word}_n \\mid \\text{class})$$\n",
    "\n",
    "ایده این است که روی هر کلمه در ایمیل تکرار کنید و در هر مرحله، احتمال را با ضرب کردن آن در مقدار $P(\\text{word} \\mid \\text{class})$ به‌روزرسانی کنید.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_email_given_class(treated_email, cls, word_frequency, class_frequency):\n",
    "    \"\"\"\n",
    "    Calculate the probability of an email being of a certain class (e.g., spam or ham) based on treated email content.\n",
    "\n",
    "    Parameters:\n",
    "    - treated_email (list): A list of treated words in the email.\n",
    "    - cls (str): The class label for the email. It can be either 'spam' or 'ham'\n",
    "    - word_frequency (dict): The dictionary containing the words frequency.\n",
    "    - class_frequency (dict): The dictionary containing the class frequency.\n",
    "\n",
    "    Returns:\n",
    "    - float: The probability of the given email belonging to the specified class.\n",
    "    \"\"\"\n",
    "\n",
    "    # prob starts at 1 because it will be updated by multiplying it with the current P(word | class) in every iteration\n",
    "    prob = 1\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    for word in None:\n",
    "        # Only perform the computation for words that exist in the word frequency dictionary\n",
    "        if word in word_frequency.keys(): \n",
    "            # Update the prob by multiplying it with P(word | class). Don't forget to add the word_frequency and class_frequency parameters!\n",
    "            prob *= None\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ec354",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_email = \"Click here to win a lottery ticket and claim your prize!\"\n",
    "treated_email = preprocess_text(example_email)\n",
    "prob_spam = prob_email_given_class(treated_email, cls = 'spam', word_frequency = word_frequency, class_frequency = class_frequency)\n",
    "prob_ham = prob_email_given_class(treated_email, cls = 'ham', word_frequency = word_frequency, class_frequency = class_frequency)\n",
    "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nP(email | spam) = {prob_spam}\\nP(email | ham) = {prob_ham}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83c796",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"font-family: arial; direction: rtl; padding: 30px; padding-top: 0; padding-bottom: 0;\">\n",
    "    \n",
    "<h2 id=\"conclusion\" style=\"color: #d42c06;\">تمرین چهارم</h2>\n",
    "\n",
    "\n",
    "در این تمرین، شما هر دو محاسبه زیر را انجام خواهید داد تا احتمال اینکه یک ایمیل اسپم یا هام باشد را محاسبه کنید:\n",
    "\n",
    "- $ P(\\text{spam}) \\cdot P(\\text{email} \\mid \\text{spam}) $\n",
    "\n",
    "- $ P(\\text{ham}) \\cdot P(\\text{email} \\mid \\text{ham})$\n",
    "\n",
    "کلاسی که مقدار بزرگتری داشته باشد، همان است که الگوریتم شما به آن ایمیل اختصاص می‌دهد. توجه داشته باشید که تابع زیر شامل پارامتری است که به تابع می‌گوید هر دو احتمال را به جای کلاسی که انتخاب شده است بازگرداند.\n",
    "\n",
    "**توجه**: خروجی یک عدد صحیح خواهد بود که کلاس ایمیل مربوطه را نشان می‌دهد. ممکن است اسپم بازگردانده شود اگر ایمیل به عنوان اسپم پیش‌بینی شده باشد و هام اگر ایمیل به عنوان هام پیش‌بینی شده باشد، اما خروجی عددی مدل به محاسبات بیشتر، مانند معیارهایی برای ارزیابی عملکرد مدل، کمک می‌کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(treated_email, word_frequency, class_frequency, return_likelihood = False):    \n",
    "    \"\"\"\n",
    "    Naive Bayes classifier for spam detection.\n",
    "\n",
    "    This function calculates the probability of an email being spam (1) or ham (0)\n",
    "    based on the Naive Bayes algorithm. It uses the conditional probabilities of the\n",
    "    treated_email given spam and ham, as well as the prior probabilities of spam and ham\n",
    "    classes. The final decision is made by comparing the calculated probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    - treated_email (list): A preprocessed representation of the input email.\n",
    "    - word_frequency (dict): The dictionary containing the words frequency.\n",
    "    - class_frequency (dict): The dictionary containing the class frequency.\n",
    "        - return_likelihood (bool): If true, it returns the likelihood of both spam and ham.\n",
    "\n",
    "    Returns:\n",
    "    If return_likelihood = False:\n",
    "        - int: 1 if the email is classified as spam, 0 if classified as ham.\n",
    "    If return_likelihood = True:\n",
    "        - tuple: A tuple with the format (spam_likelihood, ham_likelihood)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Compute P(email | spam) with the function you defined just above. Don't forget to add the word_frequency and class_frequency parameters!\n",
    "    prob_email_given_spam = None\n",
    "\n",
    "    # Compute P(email | ham) with the function you defined just above. Don't forget to add the word_frequency and class_frequency parameters!\n",
    "    prob_email_given_ham = None\n",
    "\n",
    "    # Compute P(spam) using the class_frequency dictionary and using the formula #spam emails / #total emails\n",
    "    p_spam = None\n",
    "\n",
    "    # Compute P(ham) using the class_frequency dictionary and using the formula #ham emails / #total emails\n",
    "    p_ham = None\n",
    "\n",
    "    # Compute the quantity P(spam) * P(email | spam), let's call it spam_likelihood\n",
    "    spam_likelihood = None * None\n",
    "\n",
    "    # Compute the quantity P(ham) * P(email | ham), let's call it ham_likelihood\n",
    "    ham_likelihood = None * None\n",
    "\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # In case of passing return_likelihood = True, then return the desired tuple\n",
    "    if return_likelihood == True:\n",
    "        return (spam_likelihood, ham_likelihood)\n",
    "    \n",
    "    # Compares both values and choose the class corresponding to the higher value\n",
    "    elif spam_likelihood >= ham_likelihood:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_email = \"Click here to win a lottery ticket and claim your prize!\"\n",
    "treated_email = preprocess_text(example_email)\n",
    "\n",
    "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nNaive Bayes predicts this email as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "example_email = \"Our meeting will happen in the main office. Please be there in time.\"\n",
    "treated_email = preprocess_text(example_email)\n",
    "\n",
    "print(f\"Email: {example_email}\\nEmail after preprocessing: {treated_email}\\nNaive Bayes predicts this email as: {naive_bayes(treated_email, word_frequency, class_frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e351e5",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px; padding-top: 0; padding-bottom: 0;\">\n",
    "\n",
    "<hr style=\"border-color: #fff;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598a470",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px; padding-top: 0; padding-bottom: 0;\">\n",
    "\n",
    "<hr style=\"border-color: #fff;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98af0b5",
   "metadata": {},
   "source": [
    "<div style=\"font-family: arial; direction: rtl; padding: 30px; padding-top: 0; padding-bottom: 0;\">\n",
    "    \n",
    "<h2 style=\"color: #d42c06;\">منابع و مراجع</h2>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.coursera.org/learn/machine-learning-probability-and-statistics</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<hr style=\"margin-top: 25px; border-color: #fff;\">\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
